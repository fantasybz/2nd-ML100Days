{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day100_transfer_learning_HW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkcX0YqBDaDw",
        "colab_type": "code",
        "outputId": "036bf8e8-ac42-4e9d-dfaa-fc038d2780fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import add"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdEC2n6ZDr1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dim_ordering():\n",
        "  global row_axis\n",
        "  global col_axis\n",
        "  global channel_axis\n",
        "  \n",
        "  if K.image_dim_ordering() == 'tf':\n",
        "    row_axis = 1\n",
        "    col_axis = 2\n",
        "    channel_axis = 3\n",
        "  else:\n",
        "    channel_axis = 1\n",
        "    row_axis = 2\n",
        "    col_axis = 3\n",
        "\n",
        "def _bn_relu_conv(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer = l2(1e-4), kernel_initializer = \"he_normal\"):\n",
        "    \n",
        "  def f(input_x):\n",
        "    x = keras.layers.BatchNormalization(axis = channel_axis)(input_x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    x = keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding,\n",
        "                              kernel_regularizer = kernel_regularizer, kernel_initializer = kernel_initializer)(x)\n",
        "    return x  \n",
        "    \n",
        "  return f\n",
        "  \n",
        "def _conv_bn_relu(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer = l2(1e-4), kernel_initializer = \"he_normal\"):\n",
        "    \n",
        "  def f(input_x):\n",
        "    x = keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = padding,\n",
        "                              kernel_regularizer = kernel_regularizer, kernel_initializer = kernel_initializer)(input_x)\n",
        "    x = keras.layers.BatchNormalization(axis = channel_axis)(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "      \n",
        "    return x\n",
        "    \n",
        "  return f \n",
        "  \n",
        "  \n",
        "def _shortcut(input_x, residual):\n",
        "    \n",
        "  input_shape = K.int_shape(input_x)\n",
        "  res_shape = K.int_shape(residual)\n",
        "  stride_width = int(round(input_shape[col_axis] / res_shape[col_axis]))\n",
        "  stride_height = int(round(input_shape[row_axis] / res_shape[row_axis]))\n",
        "  equal_channels = input_shape[channel_axis] == res_shape[channel_axis]\n",
        "    \n",
        "  x = input_x\n",
        "    \n",
        "  if stride_width > 1 or stride_height > 1 or equal_channels != 1:\n",
        "      \n",
        "    x = keras.layers.Conv2D(filters = res_shape[channel_axis], kernel_size = (1,1), strides = (stride_width, stride_height),\n",
        "                             padding = 'same', kernel_initializer = \"he_normal\", kernel_regularizer = l2(0.0001))(x)\n",
        "    \n",
        "  return add([x, residual])\n",
        "  \n",
        "def basic_block(filters, strides = (1,1) , first_block_of_first_layer = False):\n",
        "    \n",
        "  def f(input_x):\n",
        "      \n",
        "    x = input_x\n",
        "      \n",
        "    if first_block_of_first_layer:\n",
        "      x = keras.layers.Conv2D(filters = filters, kernel_size = (3,3), strides = strides, padding = 'same', \n",
        "                              kerne_regularizer = l2(1e-4), kernel_initializer = \"he_normal\")(x)\n",
        "    else:\n",
        "      x = _bn_relu_conv(filters = filters, strides = strides)(x)\n",
        "\n",
        "    x = _bn_relu_conv(filters = filters)(x)\n",
        "    \n",
        "    return _shortcut(input_x = input_x, residual = x)\n",
        "    \n",
        "  return f\n",
        "  \n",
        "  \n",
        "def bottleneck(filters, strides = (1,1), first_block_of_first_layer = False):\n",
        "    \n",
        "  def f(input_x):\n",
        "      \n",
        "    x = input_x\n",
        "      \n",
        "    if first_block_of_first_layer:\n",
        "      x = keras.layers.Conv2D(filters = filters, kernel_size = (1,1), strides = strides, padding = 'same',\n",
        "                               kernel_regularizer = l2(1e-4), kernel_initializer = \"he_normal\")(x)\n",
        "      \n",
        "    else:\n",
        "      x = _bn_relu_conv(filters = filters, kernel_size = (1,1), strides = strides)(x)\n",
        "      \n",
        "    x = _bn_relu_conv(filters = filters)(x)\n",
        "    x = _bn_relu_conv(filters = filters*4, kernel_size = (1,1))(x)\n",
        "      \n",
        "    return _shortcut(input_x = input_x, residual = x)\n",
        "      \n",
        "  return f\n",
        "  \n",
        "def _resnet_block(block_function, filters, repetition, is_first_layer = False):\n",
        "    \n",
        "  def f(input_x):\n",
        "      \n",
        "    for i in range(repetition):\n",
        "      init_strides = (1,1)\n",
        "      if i == 0 and is_first_layer == False:\n",
        "          init_strides = (2,2)\n",
        "            \n",
        "      if block_function == 'basic':\n",
        "        input_x = basic_block(filters = filters, strides = init_strides, first_block_of_first_layer = (i==0 and is_first_layer))(input_x)\n",
        "          \n",
        "      else:\n",
        "        input_x = bottleneck(filters = filters, strides = init_strides, first_block_of_first_layer = (i==0 and is_first_layer))(input_x)\n",
        "      \n",
        "    return input_x\n",
        "    \n",
        "  return f\n",
        "  \n",
        "  \n",
        "  \n",
        "class resnet_builder():\n",
        "  \n",
        "  def __init__(self, input_shape = (32,32,3), output_units = 10, block_function  = 'basic', repetitions = [2,2,2,2] , layer_filters = [64,128,256,512]):\n",
        "    \n",
        "    assert len(repetitions) == len(layer_filters), \"Repetitions and block_filters should have equal number\"\n",
        "    assert len(input_shape) == 3, \"Input shape should be a tuple (rows, cols, channels)\"\n",
        "    \n",
        "    \n",
        "      \n",
        "    self.input_shape = input_shape\n",
        "    self.output_units = output_units\n",
        "    self.block_function = block_function\n",
        "    self.repetitions = repetitions\n",
        "    self.layer_filters = layer_filters\n",
        "  \n",
        "  \n",
        "  def build_resnet(self):\n",
        "    \n",
        "    dim_ordering()\n",
        "    input_x = keras.layers.Input(self.input_shape)\n",
        "    x = keras.layers.Conv2D(filters = 64, kernel_size = (7,7), strides = (2,2), padding = 'same',\n",
        "                           kernel_regularizer = l2(1e-4), kernel_initializer = \"he_normal\")(input_x)\n",
        "    \n",
        "    x = keras.layers.MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'same')(x)\n",
        "    \n",
        "    for i,(filters, repetition) in enumerate(zip(self.layer_filters,self.repetitions)):\n",
        "      x = _resnet_block(self.block_function, filters, repetition, i == 0)(x)\n",
        "      \n",
        "    x = keras.layers.BatchNormalization(axis = channel_axis)(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    x_shape = K.int_shape(x)\n",
        "    x = keras.layers.AveragePooling2D(pool_size = (x_shape[row_axis], x_shape[col_axis]), strides = (1,1))(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    \n",
        "    output_x = Dense(units = self.output_units, kernel_initializer = \"he_normal\", activation = 'softmax')(x)\n",
        "    \n",
        "    model = keras.models.Model(inputs = [input_x], outputs = [output_x])\n",
        "    return model\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic5az8K_-96r",
        "colab_type": "code",
        "outputId": "641828a6-4469-42d1-de93-3b81400f3ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = cifar10.load_data()\n",
        "print(f' train_x shape : {train_x.shape}')\n",
        "print(f' train samples : {len(train_x)}')\n",
        "print(f' test samples : {len(test_x)}')\n",
        "train_x = train_x.astype('float32')\n",
        "test_x = test_x.astype('float32')\n",
        "\n",
        "train_x = train_x/255.0\n",
        "test_x = test_x/255.0\n",
        "\n",
        "train_y = keras.utils.to_categorical(train_y, 10)\n",
        "test_y = keras.utils.to_categorical(test_y, 10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            " train_x shape : (50000, 32, 32, 3)\n",
            " train samples : 50000\n",
            " test samples : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59g7iLRacHry",
        "colab_type": "code",
        "outputId": "7eac8fb5-16bb-4973-a986-8aeb4faedab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "#build the resnet 50\n",
        "resnet_builder = resnet_builder( input_shape = train_x.shape[1:] , output_units = 10, block_function = 'bottleneck', repetitions = [3,4,6,3], layer_filters = [64, 128, 256, 512] )\n",
        "resnet = resnet_builder.build_resnet()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0815 14:43:42.532280 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0815 14:43:43.685256 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0815 14:43:43.694608 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0815 14:43:43.736581 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0815 14:43:43.773086 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0815 14:43:43.774564 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0815 14:43:46.561834 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0815 14:43:52.020365 139687584274304 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xznTmY2dVjb",
        "colab_type": "code",
        "outputId": "721d5294-979f-4d98-cdb4-b2854f8d703b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resnet.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 64)   9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 8, 64)     4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 8, 8, 64)     256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 8, 8, 64)     0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 8, 8, 64)     36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 8, 8, 64)     256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 64)     0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 8, 256)    16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 256)    16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8, 8, 256)    0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 8, 8, 256)    1024        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 256)    0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 8, 8, 64)     16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 256)    16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 8, 8, 256)    0           add_1[0][0]                      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 8, 256)    1024        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 256)    0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 64)     16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 8, 8, 64)     256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 64)     36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 64)     256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 64)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 256)    16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 256)    0           add_2[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 8, 8, 256)    1024        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 256)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 4, 4, 128)    32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 4, 4, 128)    512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 4, 4, 128)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 4, 4, 128)    147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 4, 4, 128)    512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 4, 128)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 512)    131584      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 512)    66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 4, 512)    0           conv2d_15[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 4, 4, 512)    2048        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 4, 4, 512)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 128)    65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 4, 4, 128)    512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 128)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 128)    147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 4, 4, 128)    512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 512)    66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 4, 512)    0           add_4[0][0]                      \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 4, 4, 512)    2048        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 512)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 128)    65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 4, 4, 128)    512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 128)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 128)    147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 4, 4, 128)    512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 128)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 4, 4, 512)    66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           add_5[0][0]                      \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 4, 512)    2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 512)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 4, 4, 128)    512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 128)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 4, 4, 128)    512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 4, 128)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 512)    2048        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 512)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 2, 2, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 2, 2, 256)    1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 2, 2, 256)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 2, 2, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 2, 2, 256)    1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 2, 256)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 2, 2, 1024)   525312      add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 2, 2, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 2, 1024)   0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 2, 2, 1024)   4096        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 2, 2, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 2, 2, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 2, 2, 256)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 2, 2, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 2, 2, 256)    1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 2, 2, 256)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 2, 2, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 2, 2, 1024)   4096        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 2, 2, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 2, 2, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 2, 2, 256)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 2, 2, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 2, 2, 256)    1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 2, 2, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 2, 2, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 2, 2, 1024)   4096        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 2, 2, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 2, 2, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 2, 2, 256)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 2, 2, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 2, 2, 256)    1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 2, 2, 256)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 2, 2, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 2, 2, 1024)   4096        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 2, 2, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 2, 2, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 2, 2, 256)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 2, 2, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 2, 2, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 2, 2, 256)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 2, 2, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 2, 2, 1024)   4096        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 2, 2, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 2, 2, 256)    1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 2, 2, 256)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 2, 2, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 2, 2, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 2, 2, 256)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 2, 2, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 2, 2, 1024)   4096        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 2, 2, 1024)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 1, 1, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 1, 1, 512)    2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 1, 1, 512)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 1, 1, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 1, 1, 512)    2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 1, 1, 512)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 1, 1, 2048)   2099200     add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 1, 1, 2048)   0           conv2d_47[0][0]                  \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 1, 1, 2048)   8192        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 1, 1, 2048)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 1, 1, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 1, 1, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 1, 1, 512)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 1, 1, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 1, 1, 512)    2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 1, 1, 512)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 1, 1, 2048)   8192        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 1, 1, 2048)   0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 1, 1, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 1, 1, 512)    2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 1, 1, 512)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 1, 1, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 1, 1, 512)    2048        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 1, 1, 512)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 1, 1, 2048)   8192        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 1, 1, 2048)   0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           20490       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,592,586\n",
            "Trainable params: 23,547,274\n",
            "Non-trainable params: 45,312\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yribB5wCdbLW",
        "colab_type": "code",
        "outputId": "eaa69664-4c82-4ad0-e5b0-0eb225111efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "\n",
        "resnet.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])\n",
        "history = resnet.fit(train_x, train_y, batch_size = batch_size, epochs = epochs, verbose = 1, validation_data = (test_x, test_y) )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 122s 2ms/step - loss: 0.7903 - acc: 0.9172 - val_loss: 3.0137 - val_acc: 0.5896\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.7599 - acc: 0.9261 - val_loss: 1.8686 - val_acc: 0.6696\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.7652 - acc: 0.9267 - val_loss: 1.7434 - val_acc: 0.6982\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.7352 - acc: 0.9325 - val_loss: 9.7414 - val_acc: 0.2447\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.7413 - acc: 0.9338 - val_loss: 1.8083 - val_acc: 0.6926\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.7211 - acc: 0.9381 - val_loss: 1.6738 - val_acc: 0.7247\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.7203 - acc: 0.9389 - val_loss: 2.4187 - val_acc: 0.6109\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6984 - acc: 0.9400 - val_loss: 2.2472 - val_acc: 0.6220\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6759 - acc: 0.9446 - val_loss: 1.8262 - val_acc: 0.7017\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6788 - acc: 0.9446 - val_loss: 10.5638 - val_acc: 0.2399\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6600 - acc: 0.9481 - val_loss: 1.7450 - val_acc: 0.7055\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6581 - acc: 0.9463 - val_loss: 1.8319 - val_acc: 0.6757\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6511 - acc: 0.9488 - val_loss: 1.7276 - val_acc: 0.7126\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6609 - acc: 0.9475 - val_loss: 1.8351 - val_acc: 0.7058\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6533 - acc: 0.9481 - val_loss: 1.6884 - val_acc: 0.6981\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6286 - acc: 0.9523 - val_loss: 1.7902 - val_acc: 0.7100\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 109s 2ms/step - loss: 0.6281 - acc: 0.9512 - val_loss: 1.6668 - val_acc: 0.7161\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6257 - acc: 0.9525 - val_loss: 1.8368 - val_acc: 0.6928\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6239 - acc: 0.9511 - val_loss: 1.7520 - val_acc: 0.7089\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6102 - acc: 0.9541 - val_loss: 1.6816 - val_acc: 0.7138\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 110s 2ms/step - loss: 0.6111 - acc: 0.9526 - val_loss: 1.6426 - val_acc: 0.7268\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6016 - acc: 0.9553 - val_loss: 1.7260 - val_acc: 0.7113\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.6035 - acc: 0.9535 - val_loss: 1.6714 - val_acc: 0.7221\n",
            "Epoch 24/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.5927 - acc: 0.9565 - val_loss: 1.9438 - val_acc: 0.6839\n",
            "Epoch 25/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.5890 - acc: 0.9564 - val_loss: 1.7602 - val_acc: 0.6943\n",
            "Epoch 26/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.5838 - acc: 0.9566 - val_loss: 1.7951 - val_acc: 0.7008\n",
            "Epoch 27/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.5826 - acc: 0.9558 - val_loss: 1.7948 - val_acc: 0.7016\n",
            "Epoch 28/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.5729 - acc: 0.9592 - val_loss: 1.6340 - val_acc: 0.7214\n",
            "Epoch 29/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.5791 - acc: 0.9561 - val_loss: 1.6704 - val_acc: 0.7160\n",
            "Epoch 30/30\n",
            "50000/50000 [==============================] - 111s 2ms/step - loss: 0.5712 - acc: 0.9570 - val_loss: 1.9916 - val_acc: 0.6839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AzSWBO2kQ4j",
        "colab_type": "code",
        "outputId": "0b500d44-d3a4-4506-c364-68abaf7114a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(history.history['loss'], label = 'train_loss')\n",
        "plt.plot(history.history['val_loss'], label = 'valid_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(history.history['acc'], label = 'train_acc')\n",
        "plt.plot(history.history['val_acc'], label = 'valid_acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFpCAYAAACvXECGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFpCAYAAACmt+D8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEREpMApnERGRAqNwFhERKTD/P2V2B/4wnaU7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_59425gTknq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}