{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"2nd_ML100Marathon_final_kochi_v3.ipynb","version":"0.3.2","provenance":[]},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zq662N8rnkF3","colab_type":"text"},"source":["This kernel is using pre-train model to be the base model, and add some extra layers for our training model. <br />\n","Since the training dataset only has 4000 pictures, so it might be not easy to train a model with excellent feature extracting ability on this size of dataset. <br />\n","Therefore, transfer-learning is our good friend on this task, since it had pre-trained to have quite nice feature extracting ability on imagenet dataset. <br />\n","And it is pretty easy to get over 99% accuracy by using technique. <br />\n","But I still suggest to build our own model for this task. After all, we are here for learning."]},{"cell_type":"code","metadata":{"id":"Y5MQAxVfnrcS","colab_type":"code","colab":{}},"source":["from googleapiclient.discovery import build\n","import io, os\n","from googleapiclient.http import MediaIoBaseDownload\n","from google.colab import auth\n","\n","auth.authenticate_user()\n","\n","drive_service = build('drive', 'v3')\n","results = drive_service.files().list(\n","        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n","kaggle_api_key = results.get('files', [])\n","\n","filename = \"/content/.kaggle/kaggle.json\"\n","os.makedirs(os.path.dirname(filename), exist_ok=True)\n","\n","request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n","fh = io.FileIO(filename, 'wb')\n","downloader = MediaIoBaseDownload(fh, request)\n","done = False\n","while done is False:\n","    status, done = downloader.next_chunk()\n","    print(\"Download %d%%.\" % int(status.progress() * 100))\n","os.chmod(filename, 600)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3rqK68znrlC","colab_type":"code","colab":{}},"source":["!mkdir ~/.kaggle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gf6mMJYhn3eu","colab_type":"code","colab":{}},"source":["!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zEL5ESlGn6A8","colab_type":"code","colab":{}},"source":["!kaggle competitions download -c ml-marathon-final"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt7YJLROoBYI","colab_type":"code","colab":{}},"source":["import zipfile\n","\n","zip_ref = zipfile.ZipFile('data.zip', 'r')\n","zip_ref.extractall()\n","zip_ref.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vs9sWyLwn6Hf","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"Bod14itVnkF4","colab_type":"code","colab":{}},"source":["import numpy as np \n","import pandas as pd \n","import os\n","train_dir = \"./kaggle_dogcat/train/\"\n","test_dir =  \"./kaggle_dogcat/test/\"\n","\n","# Load all the filenames (Actually we can use \"flow_from_directory\" function\n","# from ImageDataGenerator to load the image, in case the momory is tight)\n","train_dog_fns = os.listdir(train_dir + \"dogs/\")\n","train_cat_fns = os.listdir(train_dir + \"cats/\")\n","test_fns = os.listdir(test_dir)\n","\n","#############################################################\n","#############################################################\n","#Dont forget to sort the file name for matching submission ID\n","test_fns.sort()\n","#############################################################\n","############################################################\n","\n","# Check the legnth of all data first\n","print(f\"dog images in training set : {len(train_dog_fns)}\")\n","print(f\"cat images in training set : {len(train_cat_fns)}\")\n","print(f\"total images in test set : {len(test_fns)}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"HYU2C2fynkF6","colab_type":"code","colab":{}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Model, Sequential\n","from pickle import dump\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization, AveragePooling2D\n","from tensorflow.keras.optimizers import Adam\n","import keras\n","import keras.backend as K\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"JVMyj2HLnkF8","colab_type":"code","colab":{}},"source":["base_model = ResNet50(include_top = False, input_shape = (224,224,3), input_tensor = None)\n","base_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"giASjH2UnkF9","colab_type":"code","colab":{}},"source":["#connect the output of our base model to new layers we created\n","x = base_model.output\n","x = AveragePooling2D(pool_size = (7,7))(x)\n","x = Flatten()(x)\n","x = Dropout(0.5)(x)\n","x = Dense(units = 1024)(x)\n","x = BatchNormalization(axis = 1)(x)\n","x = Activation(\"relu\")(x)\n","x = Dropout(0.5)(x)\n","x = Dense(units = 512)(x)\n","x = BatchNormalization(axis = 1)(x)\n","x = Activation(\"relu\")(x)\n","x = Dropout(0.5)(x)\n","output_layer = Dense(units = 2, activation = \"softmax\")(x)\n","\n","model = Model(inputs = base_model.input, outputs = output_layer)\n","optimizer = Adam(lr = 1e-4, decay = 1e-6)\n","model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"Ses9vgVunkF_","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator, load_img\n","from sklearn.utils import shuffle\n","\n","\n","#This two array is for channel-base mean subtraction preprocessing\n","#although my score had became worse after using it. \n","#pre-calculated mean value of each channel of training  dataset\n","#Pre-calculate std values of each channel of training dataset\n","train_mean = np.array([0.4914, 0.458, 0.4193], dtype = 'float64')\n","train_std = np.array([0.2591,0.2524,0.25511] , dtype = 'float64')\n","\n","def load_target_img(grayscale = False, color_mode = 'rgb'\n","                    , target_size = (224,224,3), interpolation = 'bicubic'):\n","    '''\n","    grayscale : loading image with color type or grayscale type\n","    color_mode : loading image with rgb color space and the channels are (r,g,b)\n","    target_size :Image will be rescale/resize to the target size when loading\n","    interpolation : the interpolation algorithm for rescaling/resizing the image, nearest is the most simplest and fastest one \n","    '''\n","    def f(path):\n","        return load_img(path = path, grayscale = grayscale, color_mode = color_mode,\n","                              target_size = target_size, interpolation=interpolation)\n","    return f\n","\n","# I created an image generator to generate the image in batch size\n","# In case the momery is not enough\n","\n","def image_generator(load_dir, dog_fns, cat_fns, batch_size = 32):\n","    '''\n","    load_dir : data loading path\n","    dog_fns : filenames of dog picture\n","    cat_fns : filenames of cat picture\n","    batch_size : how many data we package as a batch\n","    '''\n","    dog_load_dir = load_dir + \"dogs/\"\n","    cat_load_dir = load_dir + \"cats/\"\n","    data_batch = []\n","    label_batch = []\n","    \n","    while True:\n","        for idx in range(min(len(dog_fns),len(cat_fns))):\n","            \n","            # We should check the file is .jpg format or not\n","            if \".jpg\" in dog_fns[idx] and \".jpg\" in cat_fns[idx]:\n","                data_batch.append( np.asarray(load_target_img()(dog_load_dir + dog_fns[idx])) ) \n","                label_batch.append([1,0]) # setting dog label to 0\n","                data_batch.append( np.asarray(load_target_img()(cat_load_dir + cat_fns[idx])) )\n","                label_batch.append([0,1]) # setting cat label to 1\n","                    \n","                # When the batch collecting is reach to batch_size\n","                # The data is ready to shipping out\n","                # yield can keep the status of your function \n","                if len(data_batch) >= batch_size :\n","                    yield np.stack(data_batch), np.stack(label_batch)\n","                    data_batch = []\n","                    label_batch = []\n","                \n","def image_augmentation_generator(input_gen, image_gen):\n","    '''\n","    input_gen : input image generator, it will generate a batch of data a time\n","    image_gen : ImageDataGenerator from keras\n","    '''\n","    for data, label in input_gen:\n","        \n","        data,label = shuffle(data, label, random_state = np.random.choice(2019,1)[0])\n","        \n","        #We need to recover the original depth of image before augmentation\n","        #Since the augmentation process is based on normal image depth(8 bits, 0-255)\n","        x = image_gen.flow(data, batch_size = data.shape[0], shuffle = False)\n","        y = label\n","        \n","        #Dont forget to normalize the image back after done aumentation processing\n","        yield next(x), y\n","        \n","\n","        \n","#Since the test dataset is small (only 400 pictures), so I decided to read all of them into RAM\n","test_x = []\n","for fn in test_fns:\n","    if \".jpg\" in fn:\n","        test_x.append(np.asarray(load_target_img()(test_dir + fn)))\n","\n","#dont forget to normalize the data\n","test_x = np.asarray(test_x, dtype = 'float64') / 255.0\n","test_x.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"hK3kWGHHnkGB","colab_type":"code","colab":{}},"source":["#split the training dataset and validation dataset\n","train_dog_fns, valid_dog_fns = train_dog_fns[:1800], train_dog_fns[1800:]\n","train_cat_fns, valid_cat_fns = train_cat_fns[:1800], train_cat_fns[1800:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"QQofaMELnkGE","colab_type":"code","colab":{}},"source":["train_input_gen = image_generator(train_dir, train_dog_fns, train_cat_fns)\n","valid_input_gen = image_generator(train_dir, valid_dog_fns, valid_cat_fns)\n","\n","train_image_gen = ImageDataGenerator(\n","            rotation_range = 40,\n","            shear_range = 0.2,\n","            width_shift_range = 0.2,\n","            height_shift_range = 0.2,\n","            zoom_range = 0.2,\n","            horizontal_flip = True,\n","            rescale = 1.0/255.0\n","            )\n","\n","valid_image_gen = ImageDataGenerator( rescale = 1.0/255.0 )\n","\n","train_aug_gen = image_augmentation_generator(train_input_gen, train_image_gen)\n","valid_aug_gen = image_augmentation_generator(valid_input_gen, valid_image_gen)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqhOpAhgnkGG","colab_type":"text"},"source":["Let`s checkout some images"]},{"cell_type":"code","metadata":{"trusted":true,"id":"JqT7OrvonkGH","colab_type":"code","colab":{}},"source":["#Use next to get one batch of data and label\n","batch_data, batch_label = next(valid_aug_gen)\n","print(f\"batch data shape : {batch_data.shape}\")\n","print(f\"batch label shape : {batch_label.shape}\")\n","\n","plt.figure(figsize = (12,8))\n","nrow = 2\n","ncol = 4\n","\n","for i in range(nrow*ncol):\n","    img = batch_data[i]\n","    label = batch_label[i]\n","    plt.subplot(nrow,ncol,i+1)\n","    plt.title(f\"Label : {label}\")\n","    plt.axis('off')\n","    plt.imshow(img)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"zLILHEirnkGJ","colab_type":"code","colab":{}},"source":["epochs = 200\n","batch_size = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"CGXffAPenkGK","colab_type":"code","colab":{}},"source":["from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","weight_saving_path = \"resnet50.hdf5\"\n","\n","#ModelCheckpoint will keep monitor your monitor item, and it will save the weight automatically\n","#when the monitor item is imporved\n","checkpoint = ModelCheckpoint(weight_saving_path, monitor = \"val_loss\", verbose = 1,\n","                            save_best_only = True, mode = \"min\")\n","\n","#ReduceLROnPlateau will reduce your learning rate if the monitor item was not improve in patience times.\n","reduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", verbose = 1, mode = \"min\", patience = 10,\n","                             factor = 0.5, min_lr = 1e-8)\n","\n","#EarlyStopping will stop the training if the monitor item was not improve in patience times.\n","ES = EarlyStopping(monitor = \"val_loss\", patience = 50, mode = \"min\", verbose = 1)\n","\n","training_callbacks = [checkpoint, ES, reduce_lr]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"I37qUq8bnkGN","colab_type":"code","colab":{}},"source":["history = model.fit_generator(train_aug_gen, epochs = epochs, verbose =1, validation_data = valid_aug_gen , validation_steps = (len(valid_dog_fns) + len(valid_cat_fns))//batch_size,\n","                                steps_per_epoch = (len(train_dog_fns)+len(train_cat_fns))//batch_size, callbacks = training_callbacks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"kQln_L20nkGP","colab_type":"code","colab":{}},"source":["model.load_weights('resnet50.hdf5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"2rB1nBGpnkGR","colab_type":"code","colab":{}},"source":["plt.figure(figsize = (8,6))\n","plt.plot(history.history['loss'], label = 'train_loss')\n","plt.plot(history.history['val_loss'], label = 'valid_loss')\n","plt.title(\"Loss of resnet50 on Dogs and Cats classification\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","plt.figure(figsize = (8,6))\n","plt.plot(history.history['acc'], label = 'train_acc')\n","plt.plot(history.history['val_acc'], label = 'valid_acc')\n","plt.title(\"Accuracy of resnet50 on Dogs and Cats classification\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"52wgvly5nkGS","colab_type":"text"},"source":["Let's checkout some prediction result by image"]},{"cell_type":"code","metadata":{"trusted":true,"id":"6PAV3oH0nkGT","colab_type":"code","colab":{}},"source":["valid_data,valid_label =  next(valid_aug_gen)\n","\n","def get_label_name(prediction):\n","    return \"dog\" if prediction < 0.5 else \"cat\"\n","\n","plt.figure(figsize = (20,8))\n","nrow = 2\n","ncol = 5\n","\n","for i,(img, label) in enumerate(zip(valid_data[:10], valid_label[:10])):\n","    \n","    predict_result = model.predict(np.expand_dims(img, axis = 0))[:,1]\n","    predict_result = get_label_name(predict_result[0])\n","    ground_truth = get_label_name(label[1])\n","    \n","    plt.subplot(nrow, ncol, i+1)\n","    plt.imshow(img)\n","    plt.title(f\"predict : {predict_result}, ground truth : {ground_truth}\")\n","    plt.axis(\"off\")\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKcRGpWnqT7n","colab_type":"code","colab":{}},"source":["submission = pd.read_csv('sample_submission.csv')\n","submission['Predicted'] = model.predict(test_x)[:,1] \n","submission.to_csv(\"submission_v4.csv\",header = [\"ID\", \"Predicted\"], index = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"34RVVOD0nkGX","colab_type":"code","colab":{}},"source":["from google.colab import files\n","\n","files.download('submission_v4.csv')"],"execution_count":0,"outputs":[]}]}